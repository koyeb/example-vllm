# This Dockerfile downloads the model during buildtime instead of runtime. It
# is included primarily for demonstration purposes.

# Note: Due to image size constraints, this can *ONLY* be used for very small
#       models. Using large models can take a very long time when compressing
#       and exporting container layers during the build process. If the
#       resulting image is too large (>10GB), the deployment will fail when it
#       attempts to download the image from the registry.

FROM vllm/vllm-openai:latest

ARG HF_TOKEN
ARG MODEL_NAME="EleutherAI/pythia-70m"
ARG REVISION="main"

ENV DEBIAN_FRONTEND=noninteractive
ENV HF_HUB_ENABLE_HF_TRANSFER=1

RUN pip install huggingface_hub[cli] huggingface_hub[hf_transfer]
RUN huggingface-cli login --token $HF_TOKEN
RUN huggingface-cli download $MODEL_NAME --revision $REVISION --local-dir /workspace/model

ENTRYPOINT python3 -m vllm.entrypoints.openai.api_server \
    --model /workspace/model \
    --served-model-name $MODEL_NAME
